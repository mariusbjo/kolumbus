name: Fetch Rogaland speed limits

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "Velg modus for kjøring"
        required: true
        default: "incremental"
        type: choice
        options:
          - incremental
          - full

  schedule:
    # Daily incremental at 03:00
    - cron: "0 3 * * *"
    # Monthly full refresh at 04:00 on the 1st
    - cron: "0 4 1 * *"

jobs:
  fetch:
    runs-on: ubuntu-latest

    env:
      # Determine mode:
      # 1) If manual run → use input
      # 2) If monthly cron → full
      # 3) Otherwise → incremental
      MODE: ${{ github.event_name == 'workflow_dispatch'
                && inputs.mode
                || (github.event.schedule == '0 4 1 * *'
                    && 'full'
                    || 'incremental') }}

    steps:
      # ---------------------------------------------------------
      # CHECKOUT
      # ---------------------------------------------------------
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ---------------------------------------------------------
      # CLEAN OLD PART FILES (ONLY FOR FULL REFRESH)
      # ---------------------------------------------------------
      - name: Remove old part files (full refresh only)
        if: env.MODE == 'full'
        run: |
          echo "Full refresh – sletter alle part-filer"
          find data -maxdepth 1 -type f -name "speedlimits_part*.json" -delete

      # ---------------------------------------------------------
      # FETCH (produces chunk files directly)
      # ---------------------------------------------------------
      - name: Fetch Rogaland speed limits
        run: python scripts/fetch_speedlimits.py --mode $MODE
        timeout-minutes: 60

      # ---------------------------------------------------------
      # VALIDATE CHUNKS
      # ---------------------------------------------------------
      - name: Validate chunk files
        run: |
          shopt -s nullglob
          for f in data/speedlimits_part*.json; do
            size=$(stat -c%s "$f")
            echo "$f size: $size bytes"
            if [ "$size" -gt 100000000 ]; then
              echo "Chunk too large"
              exit 1
            fi
            python -c "import json,sys; json.load(open(sys.argv[1]))" "$f"
          done

      # ---------------------------------------------------------
      # UPLOAD ARTIFACT (ONLY CHUNKS)
      # ---------------------------------------------------------
      - name: Upload chunk files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: speedlimits-data
          path: data/speedlimits_part*.json
          retention-days: 7
