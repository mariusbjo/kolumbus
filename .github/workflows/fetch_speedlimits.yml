name: Fetch Rogaland speed limits and publish frontend

on:
  workflow_dispatch   # Workflowen kjøres manuelt fra GitHub Actions

jobs:
  fetch:
    runs-on: ubuntu-latest   # Kjør fetch-jobben på en Linux-runner

    steps:
      # 1. Hent repoet slik at scripts og data-mappen er tilgjengelig
      - name: Checkout repo
        uses: actions/checkout@v4

      # 2. Installer Python 3.11 på runneren
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 3. Cache pip-avhengigheter for raskere kjøring
      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 4. Installer Python-avhengigheter (requests)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 5. Kjør incremental fetch-scriptet som henter nye speedlimit-objekter
      #    og lagrer dem i data/speedlimits_partX.json
      - name: Fetch Rogaland speed limits
        run: python scripts/fetch_speedlimits.py
        timeout-minutes: 60

      # 6. Slå sammen alle part-filer til én stor fil (speedlimits_merged.json)
      #    og fjern duplikater basert på ID
      - name: Merge speedlimit parts
        run: python scripts/merge_speedlimits.py

      # 7. Split den store merged-filen i mindre chunk-filer (<100MB)
      #    slik at de kan publiseres til GitHub Pages
      - name: Split merged file into chunks
        run: python scripts/split_speedlimits.py

      # 8. Last opp både merged-filen og de nye part-filene som artifact
      #    slik at de kan brukes i publish-jobben
      - name: Upload merged + parts as artifact
        uses: actions/upload-artifact@v4
        with:
          name: speedlimits-data
          path: data/*.json
          retention-days: 7

  publish:
    runs-on: ubuntu-latest
    needs: fetch   # Denne jobben kjører først når fetch-jobben er ferdig

    steps:
      # 1. Hent repoet igjen for å få tilgang til web/ og public/
      - name: Checkout repo
        uses: actions/checkout@v4

      # 2. Opprett public/data-mappen som skal publiseres til gh-pages
      - name: Create public folder
        run: mkdir -p public/data

      # 3. Last ned artifact fra fetch-jobben (alle JSON-filene)
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: speedlimits-data
          path: public/data

      # 4. Fjern merged-filen fordi den er for stor for GitHub Pages (>100MB)
      - name: Remove merged file (too large for GitHub Pages)
        run: rm -f public/data/speedlimits_merged.json

      # 5. Kopier testkartet inn i public/ slik at det blir publisert
      - name: Copy test_speedlimits
        run: cp web/test_speedlimits.html public/

      # 6. Publiser public/-mappen til gh-pages-branchen
      #    force_orphan sikrer at gamle filer ikke henger igjen
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: public
          publish_branch: gh-pages
          force_orphan: true
